{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0537cf79",
   "metadata": {},
   "source": [
    "## OS-C ECB Stress Test 2022 Issue\n",
    "\n",
    "[Investigate replication of ECB stress test methodology 2022](https://github.com/os-climate/physrisk/issues/126)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d09fa53",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Spanish flood data onboarding to S3\n",
    "\n",
    "The data is 1m resolution and for 10 year return period the file weight is 1000Gb (1Tb). Given that the resolution is extremely high we can downsize it to 100m. [Data source link](http://centrodedescargas.cnig.es/CentroDescargas/index.jsp#)\n",
    "\n",
    "On the other hand, the data is provided chunked by the Spanish gov and some pre-computing must be done to upload it to an unique raster file in s3. First of all, the raster shape and affine transformation for the s3 raster file must be guessed. Secondly, every file in spanish gov must be read in 100x100 window and inserted in the new raster file.\n",
    "\n",
    "From map provided by spanish gov we can discover shape and affine transformation of raster file.\n",
    "\n",
    "Coordinate system used is: [EPSG 25830](https://epsg.org/crs_25830/ETRS89-UTM-zone-30N.html?sessionkey=cedqtluqe0)\n",
    "\n",
    "left up corner: (-110000, 4914036)  \n",
    "right up corner: (1095561, 4914036)  \n",
    "left down corner: (-110000, 3900000)  \n",
    "right down corner: (1095561, 3900000)  \n",
    "\n",
    "the range is approximate and can be narrowed\n",
    "\n",
    "width: 1095561 + 110000 = 1205561  \n",
    "height: 4914036 - 3900000 = 1014036\n",
    "\n",
    "Affine transformation adding vector:= (-110000, 3900000): = left down corner.\n",
    "\n",
    "Canary Islands to be treated as a separated raster file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f1bc2a8",
   "metadata": {},
   "source": [
    "To guess the bound exactly instead of approximate we can use the Spanish bounds lat-lon coordinates for the peninsula and transform them to EPSG 25830. Then repeat for Canary Islands."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9e3d9d0",
   "metadata": {},
   "source": [
    "## Create Zarr from shape and Affine transformation\n",
    "\n",
    "<span style=\"color:blue\">Note: the file must be located in /hazard/src/ for the dependencies to work</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e42591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import s3fs\n",
    "import zarr\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import math\n",
    "import xarray as xr\n",
    "\n",
    "from pyproj.crs import CRS\n",
    "from affine import Affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0abc8b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazard.sources.osc_zarr import OscZarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ac9bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://console-openshift-console.apps.odh-cl1.apps.os-climate.org/k8s/ns/sandbox/secrets/physrisk-s3-keys\n",
    "default_staging_bucket = \"redhat-osc-physical-landing-647521352890\"\n",
    "# OSC_S3_ACCESS_KEY, OSC_S3_SECRET_KEY\n",
    "\n",
    "# Hazard indicators bucket\n",
    "# default_staging_bucket = 'physrisk-hazard-indicators'\n",
    "prefix = \"hazard\"\n",
    "\n",
    "# Acess key and secret key are stored as env vars OSC_S3_HI_ACCESS_KEY and OSC_S3_HI_SECRET_KEY, resp.\n",
    "s3 = s3fs.S3FileSystem(\n",
    "    anon=False,\n",
    "    key=os.environ[\"OSC_S3_ACCESS_KEY\"],\n",
    "    secret=os.environ[\"OSC_S3_SECRET_KEY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bff5b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_path = os.path.join(\n",
    "    default_staging_bucket, prefix, \"hazard_MV_prueba2.zarr\"\n",
    ").replace(\"\\\\\", \"/\")\n",
    "store = s3fs.S3Map(root=group_path, s3=s3, check=False)\n",
    "root = zarr.group(store=store, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9839520d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['redhat-osc-physical-landing-647521352890/hazard/hazard.zarr',\n",
       " 'redhat-osc-physical-landing-647521352890/hazard/inventory.json',\n",
       " 'redhat-osc-physical-landing-647521352890/hazard/wri']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.ls(\"redhat-osc-physical-landing-647521352890/hazard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac55a02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['redhat-osc-physical-landing-647521352890/hazard/hazard_MV_prueba2.zarr/.zgroup']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.ls(\"redhat-osc-physical-landing-647521352890/hazard/hazard_MV_prueba.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cad50aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the zarr file was created\n",
    "group_path in s3.ls(\"redhat-osc-physical-landing-647521352890/hazard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09781e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscZ = OscZarr(bucket=default_staging_bucket, prefix=\"hazard\", s3=s3, store=store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d36f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# width: 1205561\n",
    "# height: 1014036\n",
    "\n",
    "# adding vector:= (-110000, 3900000): = left down corner.\n",
    "\n",
    "meters_resolution = 100\n",
    "x_adding = -110000\n",
    "y_adding = 3900000\n",
    "transform = Affine(meters_resolution, 0, 0, meters_resolution, x_adding, y_adding)\n",
    "crs = CRS.from_epsg(25830)\n",
    "width = math.ceil(1205561 / meters_resolution)\n",
    "height = math.ceil(1014036 / meters_resolution)\n",
    "shape = (width, height)\n",
    "return_periods = [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f439e73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zarr.core.Array '/redhat-osc-physical-landing-647521352890/hazard/hazard_MV_prueba2.zarr' (1, 12056, 10141) float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oscZ._zarr_create(\n",
    "    path=group_path,\n",
    "    shape=shape,\n",
    "    transform=transform,\n",
    "    crs=str(crs),\n",
    "    overwrite=True,\n",
    "    return_periods=return_periods,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea1a02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create xr.DataArray from s3 stored zarr object\n",
    "z = oscZ.root[group_path]\n",
    "da = xr.DataArray(data=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10222091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file\n",
    "# da = oscZ.read(path=group_path)\n",
    "# da\n",
    "\n",
    "# Return RuntimeError because of coords when creating Datarray"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df124dca",
   "metadata": {},
   "source": [
    "## Steps to populate hazard_MV_prueba.zarr for 1m resolution\n",
    "\n",
    "### Step 1: Read ESP Government flood data\n",
    "\n",
    "Returns flood depth array, x and y coordinates array in 25830 EPSG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87a8f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_one_file(path_to_file):\n",
    "    \"\"\"\n",
    "    Read spanish gov data.\n",
    "\n",
    "    Parameters:\n",
    "        path_to_file (str): full path to tif file.\n",
    "\n",
    "    Returns:\n",
    "        fld_depth (numpy array): flood depth at (x1, y1) 25830 EPSG coordinates\n",
    "        x1 (numpy array)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    src = rasterio.open(path_to_file)\n",
    "    fld_depth = src.read()\n",
    "\n",
    "    cols, rows = np.meshgrid(np.arange(src.width), np.arange(src.height))\n",
    "    x1, y1 = rasterio.transform.xy(src.transform, rows, cols)\n",
    "\n",
    "    return fld_depth.flatten(), np.array(x1).flatten(), np.array(y1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae654d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = r\"C:\\Users\\mvazquez\\Afirma Spain Dropbox\\Manuel Vazquez Gandullo\\Climate Risk\\Jupyter_Notebooks\\esp_gov_flood_data\\ESNZSNCZIMPFT010E77.tif\"\n",
    "fld_depth, x1, y1 = read_one_file(path_to_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf8fa338",
   "metadata": {},
   "source": [
    "### Step 2: Use Affine inverse to translate (x1, x2) to store (x, y)\n",
    "\n",
    "Since the Affine transformation matrix is the meter_resolution * identy we just subtract the adding vector and divide by the meter_resolution.\n",
    "\n",
    "Finally, we have to choose the points nearest to the integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ce1f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (x1 - x_adding) / meters_resolution\n",
    "y = (y1 - y_adding) / meters_resolution\n",
    "\n",
    "# Find closest x-axis coordinate\n",
    "x_ = x - x.astype(int)\n",
    "x_ = x_ == x_.min()\n",
    "\n",
    "# Find closest y-axis coordinate\n",
    "y_ = y - y.astype(int)\n",
    "y_ = y_ == y_.min()\n",
    "\n",
    "# Find common x-axis and y-axis coordinates\n",
    "index_ = np.logical_and(x_, y_)\n",
    "\n",
    "# Filter by index\n",
    "x_coord = x[index_].astype(int)\n",
    "y_coord = y[index_].astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d49d749",
   "metadata": {},
   "source": [
    "### Step 3: Populate the raster file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac169636",
   "metadata": {},
   "outputs": [],
   "source": [
    "da.data[x_coord, y_coord] = fld_depth[index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcfc0ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscZ.write(path=group_path, da=da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6043456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using root object. Better to use oscZ object\n",
    "\n",
    "\"\"\"\n",
    "create_dataset(name, **kwargs) method of zarr.hierarchy.Group instance\n",
    "    Create an array.\n",
    "    \n",
    "    Arrays are known as \"datasets\" in HDF5 terminology. For compatibility\n",
    "    with h5py, Zarr groups also implement the require_dataset() method.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name : string\n",
    "        Array name.\n",
    "    data : array-like, optional\n",
    "        Initial data.\n",
    "    shape : int or tuple of ints\n",
    "        Array shape.\n",
    "    chunks : int or tuple of ints, optional\n",
    "        Chunk shape. If not provided, will be guessed from `shape` and\n",
    "        `dtype`.\n",
    "    dtype : string or dtype, optional\n",
    "        NumPy dtype.\n",
    "    compressor : Codec, optional\n",
    "        Primary compressor.\n",
    "    fill_value : object\n",
    "        Default value to use for uninitialized portions of the array.\n",
    "\n",
    "\n",
    "\n",
    "root.create_dataset(name='prueba',\n",
    "                    data = np.array([[0,1], [1,6]]),\n",
    "                    shape = (2,2),\n",
    "                    chunks = (1000, 1000),\n",
    "                    dtype = 'f4')\n",
    "\n",
    "trans_members = [\n",
    "    transform.a,\n",
    "    transform.b,\n",
    "    transform.c,\n",
    "    transform.d,\n",
    "    transform.e,\n",
    "    transform.f,\n",
    "]\n",
    "mat3x3 = [x * 1.0 for x in trans_members] + [0.0, 0.0, 1.0] # Why adding this ??\n",
    "root.attrs[\"crs\"] = str(crs)\n",
    "root.attrs[\"transform_mat3x3\"] = mat3x3 \n",
    "if return_periods is not None:\n",
    "    root.attrs[\"index_values\"] = return_periods\n",
    "    root.attrs[\"index_name\"] = \"return period (years)\"\n",
    "\n",
    "# Read the file\n",
    "root['prueba']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c4eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to remove a file inside a bucket\n",
    "\n",
    "\"\"\"\"\n",
    "import boto3\n",
    "boto_c = boto3.client('s3', aws_access_key_id=os.environ[\"OSC_S3_ACCESS_KEY\"], aws_secret_access_key=os.environ[\"OSC_S3_SECRET_KEY\"])\n",
    "\n",
    "to_remove = boto_c.list_objects_v2(Bucket=default_staging_bucket, Prefix='hazard/hazard_MV_prueba.zarr')['Contents']\n",
    "\n",
    "keys = [item['Key'] for item in to_remove]\n",
    "\n",
    "for key_ in keys:\n",
    "    boto_c.delete_object(Bucket=default_staging_bucket, Key=key_)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79230074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['redhat-osc-physical-landing-647521352890/hazard/hazard.zarr/chronic_heat/osc/v1/mean_degree_days_above_18c_historical_1980/.zarray',\n",
       " 'redhat-osc-physical-landing-647521352890/hazard/hazard.zarr/chronic_heat/osc/v1/mean_degree_days_above_18c_historical_1980/.zattrs',\n",
       " 'redhat-osc-physical-landing-647521352890/hazard/hazard.zarr/chronic_heat/osc/v1/mean_degree_days_above_18c_historical_1980/0.0.0']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.ls(\n",
    "    \"redhat-osc-physical-landing-647521352890/hazard/hazard.zarr/chronic_heat/osc/v1/mean_degree_days_above_18c_historical_1980\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'redhat-osc-physical-landing-647521352890/redhat-osc-physicalrisk-upload'\n",
    " 'redhat-osc-physical-landing-647521352890/demo_test-0518145310',\n",
    " 'redhat-osc-physical-landing-647521352890/demo_test-0518191846',\n",
    " 'redhat-osc-physical-landing-647521352890/demo_test-0518201258',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b271b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
