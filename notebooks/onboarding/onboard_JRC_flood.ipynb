{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a758a2e",
   "metadata": {},
   "source": [
    "## Onboard Joint Research Center (JRC) data to OS-C S3\n",
    "\n",
    "The data is flood depth historical return period data and can be found at [JRC data catalog](https://data.jrc.ec.europa.eu/dataset/1d128b6c-a4ee-4858-9e34-6210707f3c81). The methodology is detailed at [\"A new dataset of river flood hazard maps for Europe and the Mediterranean Basin\" by  Francesco Dottori, Lorenzo Alfieri, Alessandra Bianchi, Jon Skoien, and Peter Salamon](https://essd.copernicus.org/articles/14/1549/2022/).\n",
    "\n",
    "The provide six different return periods: 10, 20, 50, 100, 200 and 500 years.\n",
    "\n",
    "The coordinates system of the map is EPSG:3035 (ETRS89-extended / LAEA Europe) and needs to be translated to Latitud-Longitud coordinate system. See EPSG official website for more information. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f1bc2a8",
   "metadata": {},
   "source": [
    "To guess the bound exactly instead of approximate we can use the Spanish bounds lat-lon coordinates for the peninsula and transform them to EPSG 25830. Then repeat for Canary Islands."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9e3d9d0",
   "metadata": {},
   "source": [
    "## Create Zarr from shape and Affine transformation\n",
    "\n",
    "<span style=\"color:blue\">Note: the file must be located in /hazard/src/ for the dependencies to work</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e42591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\xarray\\backends\\cfgrib_.py:27: UserWarning: Failed to load cfgrib - most likely there is a problem accessing the ecCodes library. Try `import cfgrib` to get the full error message\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import s3fs\n",
    "import zarr\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import math\n",
    "import xarray as xr\n",
    "\n",
    "from pyproj.crs import CRS\n",
    "from affine import Affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0abc8b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazard.sources.osc_zarr import OscZarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ac9bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://console-openshift-console.apps.odh-cl1.apps.os-climate.org/k8s/ns/sandbox/secrets/physrisk-s3-keys\n",
    "# default_staging_bucket = 'redhat-osc-physical-landing-647521352890'\n",
    "# OSC_S3_ACCESS_KEY, OSC_S3_SECRET_KEY\n",
    "\n",
    "# Hazard indicators bucket\n",
    "#default_staging_bucket = 'physrisk-hazard-indicators'\n",
    "#prefix = 'hazard'\n",
    "\n",
    "# Acess key and secret key are stored as env vars OSC_S3_HI_ACCESS_KEY and OSC_S3_HI_SECRET_KEY, resp.\n",
    "#s3 = s3fs.S3FileSystem(anon=False, key=os.environ[\"OSC_S3_HI_ACCESS_KEY\"], secret=os.environ[\"OSC_S3_HI_SECRET_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8175f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://console-openshift-console.apps.odh-cl1.apps.os-climate.org/k8s/ns/sandbox/secrets/physrisk-dev-s3-keys\n",
    "# Hazard indicators bucket\n",
    "default_staging_bucket = 'physrisk-hazard-indicators-dev01'\n",
    "prefix = 'hazard'\n",
    "\n",
    "# Acess key and secret key are stored as env vars OSC_S3_HI_ACCESS_KEY and OSC_S3_HI_SECRET_KEY, resp.\n",
    "s3 = s3fs.S3FileSystem(anon=False, key=os.environ[\"OSC_S3_HIdev01_ACCESS_KEY\"], secret=os.environ[\"OSC_S3_HIdev01_SECRET_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bff5b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_path = os.path.join(default_staging_bucket, prefix, \"riverflood_JRC_RP_hist.zarr\").replace('\\\\','/')\n",
    "store = s3fs.S3Map(root=group_path, s3=s3, check=False)\n",
    "root = zarr.group(store=store, overwrite=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0201134d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510c0616140f4349af997bc7db464efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tree(nodes=(Node(disabled=True, name='/'),))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9839520d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['physrisk-hazard-indicators-dev01/hazard/riverflood_JRC_RP_hist.zarr']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.ls(\"physrisk-hazard-indicators-dev01/hazard/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cad50aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the zarr file was created\n",
    "group_path in s3.ls(\"physrisk-hazard-indicators-dev01/hazard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09781e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscZ = OscZarr(bucket=default_staging_bucket,\n",
    "        prefix=\"hazard\",\n",
    "        s3=s3,\n",
    "        store=store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15a28bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_hazard = os.path.join(os.getenv(\"physical_risk_database\"), 'hazard')\n",
    "\n",
    "hazard_type = 'Flood'\n",
    "datasource = 'JRC'\n",
    "data_filename = 'ESNZSNCZIMPFT010E77.tif'\n",
    "\n",
    "inputfile_path = os.path.join(base_path_hazard, hazard_type, datasource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17d36f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_period = '010'\n",
    "data_filename = 'floodmap_EFAS_RP{}_C.tif'.format(return_period, return_period)\n",
    "inputfile = os.path.join(inputfile_path, data_filename)\n",
    "\n",
    "src = rasterio.open(inputfile)\n",
    "\n",
    "transform = src.transform\n",
    "crs = CRS.from_epsg(3035)\n",
    "width = src.width\n",
    "height = src.height\n",
    "shape = (height, width)\n",
    "\n",
    "return_periods_str = ['010', '020', '050', '100', '200', '500']\n",
    "return_periods = [int(rt) for rt in return_periods_str]\n",
    "\n",
    "src.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f439e73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zarr.core.Array '/physrisk-hazard-indicators-dev01/hazard/riverflood_JRC_RP_hist.zarr/prueba' (6, 45242, 63976) float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_path_array = os.path.join(group_path, 'prueba')\n",
    "oscZ._zarr_create(path=group_path_array,\n",
    "                  shape = shape,\n",
    "                  transform = transform,\n",
    "                  crs = str(crs),\n",
    "                  overwrite=False,\n",
    "                  return_periods=return_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5692124a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"zarr-info\"><tbody><tr><th style=\"text-align: left\">Name</th><td style=\"text-align: left\">/physrisk-hazard-indicators-dev01/hazard/riverflood_JRC_RP_hist.zarr/prueba</td></tr><tr><th style=\"text-align: left\">Type</th><td style=\"text-align: left\">zarr.core.Array</td></tr><tr><th style=\"text-align: left\">Data type</th><td style=\"text-align: left\">float32</td></tr><tr><th style=\"text-align: left\">Shape</th><td style=\"text-align: left\">(6, 45242, 63976)</td></tr><tr><th style=\"text-align: left\">Chunk shape</th><td style=\"text-align: left\">(6, 1000, 1000)</td></tr><tr><th style=\"text-align: left\">Order</th><td style=\"text-align: left\">C</td></tr><tr><th style=\"text-align: left\">Read-only</th><td style=\"text-align: left\">False</td></tr><tr><th style=\"text-align: left\">Compressor</th><td style=\"text-align: left\">Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)</td></tr><tr><th style=\"text-align: left\">Store type</th><td style=\"text-align: left\">zarr.storage.FSStore</td></tr><tr><th style=\"text-align: left\">No. bytes</th><td style=\"text-align: left\">69465652608 (64.7G)</td></tr><tr><th style=\"text-align: left\">No. bytes stored</th><td style=\"text-align: left\">706</td></tr><tr><th style=\"text-align: left\">Storage ratio</th><td style=\"text-align: left\">98393275.6</td></tr><tr><th style=\"text-align: left\">Chunks initialized</th><td style=\"text-align: left\">0/2944</td></tr></tbody></table>"
      ],
      "text/plain": [
       "Name               : /physrisk-hazard-indicators-\n",
       "                   : dev01/hazard/riverflood_JRC_RP_hist.zarr/prueba\n",
       "Type               : zarr.core.Array\n",
       "Data type          : float32\n",
       "Shape              : (6, 45242, 63976)\n",
       "Chunk shape        : (6, 1000, 1000)\n",
       "Order              : C\n",
       "Read-only          : False\n",
       "Compressor         : Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)\n",
       "Store type         : zarr.storage.FSStore\n",
       "No. bytes          : 69465652608 (64.7G)\n",
       "No. bytes stored   : 706\n",
       "Storage ratio      : 98393275.6\n",
       "Chunks initialized : 0/2944"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oscZ.root[group_path_array].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1a02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create xr.DataArray from s3 stored zarr object\n",
    "\n",
    "# This will break arise memory error\n",
    "#z = oscZ.root[group_path_array]\n",
    "#da = xr.DataArray(data=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9681e1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zarr.core.Array '/physrisk-hazard-indicators-dev01/hazard/riverflood_JRC_RP_hist.zarr/prueba' (6, 45242, 63976) float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = oscZ.root[group_path_array]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10222091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file\n",
    "# da = oscZ.read(path=group_path)\n",
    "#da\n",
    "\n",
    "# Return RuntimeError because of coords when creating Datarray"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df124dca",
   "metadata": {},
   "source": [
    "## Steps to populate riverflood_JRC_RP_hist.zarr for 100m resolution\n",
    "\n",
    "### Step 1: Read JRC flood data\n",
    "\n",
    "Returns flood depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87a8f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_one_file(inputfile):\n",
    "    \"\"\"\n",
    "    Read JRC data.\n",
    "\n",
    "    Parameters:\n",
    "        path_to_file (str): full path to tif file.\n",
    "\n",
    "    Returns:\n",
    "        fld_depth (numpy array): flood depth at (x1, y1) 3035 EPSG coordinates\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    src = rasterio.open(inputfile)\n",
    "    fld_depth = src.read()\n",
    "\n",
    "    return fld_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d28c22b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_window(src, height_pos, width_pos, chunck_size):\n",
    "    \"\"\"\n",
    "    Read JRC data.\n",
    "\n",
    "    Parameters:\n",
    "        path_to_file (str): full path to tif file.\n",
    "\n",
    "    Returns:\n",
    "        fld_depth (numpy array): flood depth at (x1, y1) 3035 EPSG coordinates\n",
    "\n",
    "    \"\"\"\n",
    "    window = rasterio.windows.Window(width_pos, height_pos, chunck_size, chunck_size)\n",
    "    band = src.read(1, window=window)\n",
    "\n",
    "    to_impute = band == src.nodata\n",
    "    band[to_impute] = 0\n",
    "\n",
    "    return band"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d49d749",
   "metadata": {},
   "source": [
    "### Step 2: Populate the raster file for every return period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac169636",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunck_size = 1000\n",
    "\n",
    "for rt_i, rt in enumerate(return_periods_str):\n",
    "\n",
    "    data_filename = 'floodmap_EFAS_RP{}_C.tif'.format(rt, rt)\n",
    "    inputfile = os.path.join(inputfile_path, data_filename)\n",
    "\n",
    "    src = rasterio.open(inputfile)\n",
    "\n",
    "    #da.data[rt_i,:,:] = fld_depth\n",
    "    for height_pos in range(0, height, chunck_size):\n",
    "        for width_pos in range(0, width, chunck_size):\n",
    "\n",
    "            band = read_window(src, height_pos, width_pos, chunck_size)\n",
    "\n",
    "            #z[rt_i,height_pos:height_pos+chunck_size, width_pos:width_pos+chunck_size] = fld_depth[0,height_pos:height_pos+chunck_size,width_pos:width_pos+chunck_size]\n",
    "\n",
    "            z[rt_i,height_pos:height_pos+chunck_size, width_pos:width_pos+chunck_size] = band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46420581",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_i = 0\n",
    "rt = '010'\n",
    "\n",
    "data_filename = 'floodmap_EFAS_RP{}_C.tif'.format(rt, rt)\n",
    "inputfile = os.path.join(inputfile_path, data_filename)\n",
    "\n",
    "src = rasterio.open(inputfile)\n",
    "\n",
    "#da.data[rt_i,:,:] = fld_depth\n",
    "for height_pos in range(0, height, chunck_size):\n",
    "    for width_pos in range(0, width, chunck_size):\n",
    "\n",
    "        band = read_window(src, height_pos, width_pos, chunck_size)\n",
    "\n",
    "        #z[rt_i,height_pos:height_pos+chunck_size, width_pos:width_pos+chunck_size] = fld_depth[0,height_pos:height_pos+chunck_size,width_pos:width_pos+chunck_size]\n",
    "\n",
    "        z[rt_i,height_pos:height_pos+chunck_size, width_pos:width_pos+chunck_size] = band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf8948f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.402823e+38"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0,435,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8437a2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 [0, 1, 2]\n",
      "3 3 [3, 4, 5]\n",
      "6 3 [6, 7, 8]\n",
      "9 3 [9, 10, 11]\n",
      "12 3 [12, 13, 14]\n",
      "15 3 [15, 16, 17]\n",
      "18 3 [18, 19, 20]\n",
      "21 3 [21, 22]\n"
     ]
    }
   ],
   "source": [
    "size = 3\n",
    "a = list(range(23))\n",
    "for pos in range(0, len(a), size):\n",
    "    print(pos, size, a[pos:pos+size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7dc27c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 22]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[21:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a41fa3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0,0,0] == src.nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99144ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 45242, 63976)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fld_depth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcfc0ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscZ.write(path = group_path,\n",
    "           da = da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6043456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using root object. Better to use oscZ object\n",
    "\n",
    "\"\"\"\n",
    "create_dataset(name, **kwargs) method of zarr.hierarchy.Group instance\n",
    "    Create an array.\n",
    "    \n",
    "    Arrays are known as \"datasets\" in HDF5 terminology. For compatibility\n",
    "    with h5py, Zarr groups also implement the require_dataset() method.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name : string\n",
    "        Array name.\n",
    "    data : array-like, optional\n",
    "        Initial data.\n",
    "    shape : int or tuple of ints\n",
    "        Array shape.\n",
    "    chunks : int or tuple of ints, optional\n",
    "        Chunk shape. If not provided, will be guessed from `shape` and\n",
    "        `dtype`.\n",
    "    dtype : string or dtype, optional\n",
    "        NumPy dtype.\n",
    "    compressor : Codec, optional\n",
    "        Primary compressor.\n",
    "    fill_value : object\n",
    "        Default value to use for uninitialized portions of the array.\n",
    "\n",
    "\n",
    "\n",
    "root.create_dataset(name='prueba',\n",
    "                    data = np.array([[0,1], [1,6]]),\n",
    "                    shape = (2,2),\n",
    "                    chunks = (1000, 1000),\n",
    "                    dtype = 'f4')\n",
    "\n",
    "trans_members = [\n",
    "    transform.a,\n",
    "    transform.b,\n",
    "    transform.c,\n",
    "    transform.d,\n",
    "    transform.e,\n",
    "    transform.f,\n",
    "]\n",
    "mat3x3 = [x * 1.0 for x in trans_members] + [0.0, 0.0, 1.0] # Why adding this ??\n",
    "root.attrs[\"crs\"] = str(crs)\n",
    "root.attrs[\"transform_mat3x3\"] = mat3x3 \n",
    "if return_periods is not None:\n",
    "    root.attrs[\"index_values\"] = return_periods\n",
    "    root.attrs[\"index_name\"] = \"return period (years)\"\n",
    "\n",
    "# Read the file\n",
    "root['prueba']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c4eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to remove a file inside a bucket\n",
    "\n",
    "\"\"\"\"\n",
    "import boto3\n",
    "boto_c = boto3.client('s3', aws_access_key_id=os.environ[\"OSC_S3_ACCESS_KEY\"], aws_secret_access_key=os.environ[\"OSC_S3_SECRET_KEY\"])\n",
    "\n",
    "to_remove = boto_c.list_objects_v2(Bucket=default_staging_bucket, Prefix='hazard/hazard_MV_prueba.zarr')['Contents']\n",
    "\n",
    "keys = [item['Key'] for item in to_remove]\n",
    "\n",
    "for key_ in keys:\n",
    "    boto_c.delete_object(Bucket=default_staging_bucket, Key=key_)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
