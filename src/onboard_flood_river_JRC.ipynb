{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0918eac8",
   "metadata": {},
   "source": [
    "## Onboard River Flood Hazard Maps from Joint Research Center (JRC) to OS-C S3 bucket\n",
    "\n",
    "The data is flood depth historical return period data and can be found at [JRC data catalog](https://data.jrc.ec.europa.eu/dataset/1d128b6c-a4ee-4858-9e34-6210707f3c81). The methodology is detailed at [\"A new dataset of river flood hazard maps for Europe and the Mediterranean Basin\" by  Francesco Dottori, Lorenzo Alfieri, Alessandra Bianchi, Jon Skoien, and Peter Salamon](https://essd.copernicus.org/articles/14/1549/2022/).\n",
    "\n",
    "The provide six different return periods: 10, 20, 50, 100, 200 and 500 years.\n",
    "\n",
    "The resolution is 100m."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413beffc",
   "metadata": {},
   "source": [
    "## Create Zarr from shape and Affine transformation\n",
    "\n",
    "<span style=\"color:blue\">Note: this file must be located in /hazard/src/ for the dependencies to work</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d1053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\xarray\\backends\\cfgrib_.py:27: UserWarning: Failed to load cfgrib - most likely there is a problem accessing the ecCodes library. Try `import cfgrib` to get the full error message\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import s3fs\n",
    "import zarr\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import math\n",
    "import xarray as xr\n",
    "\n",
    "from pyproj.crs import CRS\n",
    "from affine import Affine\n",
    "\n",
    "from hazard.sources.osc_zarr import OscZarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf0b9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8214c8ed1b44a687372595cff733f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tree(nodes=(Node(disabled=True, name='/', nodes=(Node(disabled=True, name='physrisk-hazard-indicators-dev01', â€¦"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://console-openshift-console.apps.odh-cl1.apps.os-climate.org/k8s/ns/sandbox/secrets/physrisk-dev-s3-keys\n",
    "# Hazard indicators bucket\n",
    "default_staging_bucket = 'physrisk-hazard-indicators-dev01'\n",
    "prefix = 'hazard'\n",
    "\n",
    "# Acess key and secret key are stored as env vars OSC_S3_HI_ACCESS_KEY and OSC_S3_HI_SECRET_KEY, resp.\n",
    "s3 = s3fs.S3FileSystem(anon=False, key=os.environ[\"OSC_S3_HIdev01_ACCESS_KEY\"], secret=os.environ[\"OSC_S3_HIdev01_SECRET_KEY\"])\n",
    "\n",
    "# Define zarr group\n",
    "zarr_storage = 'hazard.zarr'\n",
    "group_path = os.path.join(default_staging_bucket, prefix, zarr_storage).replace('\\\\','/')\n",
    "store = s3fs.S3Map(root=group_path, s3=s3, check=False)\n",
    "root = zarr.group(store=store, overwrite=False) \n",
    "\n",
    "# zarr_ storage tree\n",
    "root.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f36217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['physrisk-hazard-indicators-dev01/hazard/hazard.zarr',\n",
       " 'physrisk-hazard-indicators-dev01/hazard/riverflood_JRC_RP_hist.zarr']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List folder files\n",
    "s3.ls(os.path.join(default_staging_bucket, prefix).replace('\\\\','/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b87b92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create OscZarr object to interact with the bucket.\n",
    "oscZ = OscZarr(bucket=default_staging_bucket,\n",
    "        prefix=prefix,\n",
    "        s3=s3,\n",
    "        store=store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53437d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the tif files. There is one tif file per return period\n",
    "\n",
    "base_path_hazard = os.path.join(os.getenv(\"physical_risk_database\"), 'hazard')\n",
    "\n",
    "hazard_type = 'Flood'\n",
    "datasource = 'JRC'\n",
    "\n",
    "inputfile_path = os.path.join(base_path_hazard, hazard_type, datasource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9adaa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read one tif file to get the metadata: transform, crs, width, height and shape\n",
    "\n",
    "return_period = '010'\n",
    "data_filename = 'floodmap_EFAS_RP{}_C.tif'.format(return_period, return_period)\n",
    "inputfile = os.path.join(inputfile_path, data_filename)\n",
    "\n",
    "src = rasterio.open(inputfile)\n",
    "\n",
    "transform = src.transform\n",
    "crs = CRS.from_epsg(3035)\n",
    "width = src.width\n",
    "height = src.height\n",
    "shape = (height, width)\n",
    "\n",
    "return_periods_str = ['010', '020', '050', '100', '200', '500']\n",
    "return_periods = [int(rt) for rt in return_periods_str]\n",
    "\n",
    "src.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e90c456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zarr.core.Array '/physrisk-hazard-indicators-dev01/hazard/hazard.zarr/flood_river_hist_RP_JRC' (6, 45242, 63976) float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data file inside zarr group with name dataset_name\n",
    "\n",
    "# Name standard is: hazard_type + _ + hazard_subtype (if exists) + '_' + hist or scenario + '_' RP (return period) or event/ emulated + '_' + data_provider\n",
    "dataset_name = 'flood_river_hist_RP_JRC'\n",
    "group_path_array = os.path.join(group_path, dataset_name)\n",
    "oscZ._zarr_create(path=group_path_array,\n",
    "                  shape = shape,\n",
    "                  transform = transform,\n",
    "                  crs = str(crs),\n",
    "                  overwrite=False,\n",
    "                  return_periods=return_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1ba6dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"zarr-info\"><tbody><tr><th style=\"text-align: left\">Name</th><td style=\"text-align: left\">/physrisk-hazard-indicators-dev01/hazard/hazard.zarr/flood_river_hist_RP_JRC</td></tr><tr><th style=\"text-align: left\">Type</th><td style=\"text-align: left\">zarr.core.Array</td></tr><tr><th style=\"text-align: left\">Data type</th><td style=\"text-align: left\">float32</td></tr><tr><th style=\"text-align: left\">Shape</th><td style=\"text-align: left\">(6, 45242, 63976)</td></tr><tr><th style=\"text-align: left\">Chunk shape</th><td style=\"text-align: left\">(6, 1000, 1000)</td></tr><tr><th style=\"text-align: left\">Order</th><td style=\"text-align: left\">C</td></tr><tr><th style=\"text-align: left\">Read-only</th><td style=\"text-align: left\">False</td></tr><tr><th style=\"text-align: left\">Compressor</th><td style=\"text-align: left\">Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)</td></tr><tr><th style=\"text-align: left\">Store type</th><td style=\"text-align: left\">zarr.storage.FSStore</td></tr><tr><th style=\"text-align: left\">No. bytes</th><td style=\"text-align: left\">69465652608 (64.7G)</td></tr><tr><th style=\"text-align: left\">No. bytes stored</th><td style=\"text-align: left\">706</td></tr><tr><th style=\"text-align: left\">Storage ratio</th><td style=\"text-align: left\">98393275.6</td></tr><tr><th style=\"text-align: left\">Chunks initialized</th><td style=\"text-align: left\">0/2944</td></tr></tbody></table>"
      ],
      "text/plain": [
       "Name               : /physrisk-hazard-indicators-\n",
       "                   : dev01/hazard/hazard.zarr/flood_river_hist_RP_JRC\n",
       "Type               : zarr.core.Array\n",
       "Data type          : float32\n",
       "Shape              : (6, 45242, 63976)\n",
       "Chunk shape        : (6, 1000, 1000)\n",
       "Order              : C\n",
       "Read-only          : False\n",
       "Compressor         : Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)\n",
       "Store type         : zarr.storage.FSStore\n",
       "No. bytes          : 69465652608 (64.7G)\n",
       "No. bytes stored   : 706\n",
       "Storage ratio      : 98393275.6\n",
       "Chunks initialized : 0/2944"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = oscZ.root[group_path_array]\n",
    "z.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c374d9",
   "metadata": {},
   "source": [
    "## Steps to populate hazard.zarr/flood_river_hist_RP_JRC\n",
    "\n",
    "### Step 1: Read tif files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "467696c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_window(src, height_pos, width_pos, chunck_size):\n",
    "    \"\"\"\n",
    "    Read JRC data.\n",
    "\n",
    "    Parameters:\n",
    "        path_to_file (str): full path to tif file.\n",
    "\n",
    "    Returns:\n",
    "        fld_depth (numpy array): flood depth at (x1, y1) 3035 EPSG coordinates\n",
    "\n",
    "    \"\"\"\n",
    "    window = rasterio.windows.Window(width_pos, height_pos, chunck_size, chunck_size)\n",
    "    band = src.read(1, window=window)\n",
    "\n",
    "    to_impute = band == src.nodata\n",
    "    band[to_impute] = 0\n",
    "\n",
    "    return band"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764d15ab",
   "metadata": {},
   "source": [
    "### Step 2: Populate the raster file for every return period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf52807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunck_size = 1000\n",
    "\n",
    "for rt_i, rt in enumerate(return_periods_str):\n",
    "\n",
    "    data_filename = 'floodmap_EFAS_RP{}_C.tif'.format(rt, rt)\n",
    "    inputfile = os.path.join(inputfile_path, data_filename)\n",
    "\n",
    "    src = rasterio.open(inputfile)\n",
    "\n",
    "    #da.data[rt_i,:,:] = fld_depth\n",
    "    for height_pos in range(0, height, chunck_size):\n",
    "        for width_pos in range(0, width, chunck_size):\n",
    "\n",
    "            band = read_window(src, height_pos, width_pos, chunck_size)\n",
    "\n",
    "            z[rt_i,height_pos:height_pos+chunck_size, width_pos:width_pos+chunck_size] = band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abb1f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_i = 0\n",
    "rt = '010'\n",
    "chunck_size = 1000\n",
    "data_filename = 'floodmap_EFAS_RP{}_C.tif'.format(rt, rt)\n",
    "inputfile = os.path.join(inputfile_path, data_filename)\n",
    "\n",
    "src = rasterio.open(inputfile)\n",
    "\n",
    "height_pos = 0\n",
    "width_pos = 0\n",
    "\n",
    "band = read_window(src, height_pos, width_pos, chunck_size)\n",
    "z[rt_i,height_pos:height_pos+chunck_size, width_pos:width_pos+chunck_size] = band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b324cee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 [0, 1, 2]\n",
      "3 3 [3, 4, 5]\n",
      "6 3 [6, 7, 8]\n",
      "9 3 [9, 10, 11]\n",
      "12 3 [12, 13, 14]\n",
      "15 3 [15, 16, 17]\n",
      "18 3 [18, 19, 20]\n",
      "21 3 [21, 22]\n"
     ]
    }
   ],
   "source": [
    "size = 3\n",
    "a = list(range(23))\n",
    "for pos in range(0, len(a), size):\n",
    "    print(pos, size, a[pos:pos+size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58bc9c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 22]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[21:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "876e9313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0,0,0] == src.nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de3791d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 45242, 63976)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fld_depth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20aa1edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscZ.write(path = group_path,\n",
    "           da = da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a12243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using root object. Better to use oscZ object\n",
    "\n",
    "\"\"\"\n",
    "create_dataset(name, **kwargs) method of zarr.hierarchy.Group instance\n",
    "    Create an array.\n",
    "    \n",
    "    Arrays are known as \"datasets\" in HDF5 terminology. For compatibility\n",
    "    with h5py, Zarr groups also implement the require_dataset() method.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name : string\n",
    "        Array name.\n",
    "    data : array-like, optional\n",
    "        Initial data.\n",
    "    shape : int or tuple of ints\n",
    "        Array shape.\n",
    "    chunks : int or tuple of ints, optional\n",
    "        Chunk shape. If not provided, will be guessed from `shape` and\n",
    "        `dtype`.\n",
    "    dtype : string or dtype, optional\n",
    "        NumPy dtype.\n",
    "    compressor : Codec, optional\n",
    "        Primary compressor.\n",
    "    fill_value : object\n",
    "        Default value to use for uninitialized portions of the array.\n",
    "\n",
    "\n",
    "\n",
    "root.create_dataset(name='prueba',\n",
    "                    data = np.array([[0,1], [1,6]]),\n",
    "                    shape = (2,2),\n",
    "                    chunks = (1000, 1000),\n",
    "                    dtype = 'f4')\n",
    "\n",
    "trans_members = [\n",
    "    transform.a,\n",
    "    transform.b,\n",
    "    transform.c,\n",
    "    transform.d,\n",
    "    transform.e,\n",
    "    transform.f,\n",
    "]\n",
    "mat3x3 = [x * 1.0 for x in trans_members] + [0.0, 0.0, 1.0] # Why adding this ??\n",
    "root.attrs[\"crs\"] = str(crs)\n",
    "root.attrs[\"transform_mat3x3\"] = mat3x3 \n",
    "if return_periods is not None:\n",
    "    root.attrs[\"index_values\"] = return_periods\n",
    "    root.attrs[\"index_name\"] = \"return period (years)\"\n",
    "\n",
    "# Read the file\n",
    "root['prueba']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a9431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to remove a file inside a bucket\n",
    "\n",
    "\"\"\"\"\n",
    "import boto3\n",
    "boto_c = boto3.client('s3', aws_access_key_id=os.environ[\"OSC_S3_ACCESS_KEY\"], aws_secret_access_key=os.environ[\"OSC_S3_SECRET_KEY\"])\n",
    "\n",
    "to_remove = boto_c.list_objects_v2(Bucket=default_staging_bucket, Prefix='hazard/hazard_MV_prueba.zarr')['Contents']\n",
    "\n",
    "keys = [item['Key'] for item in to_remove]\n",
    "\n",
    "for key_ in keys:\n",
    "    boto_c.delete_object(Bucket=default_staging_bucket, Key=key_)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
